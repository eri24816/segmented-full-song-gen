{
    "cells": [
        {
            "cell_type": "code",
            "execution_count": 1,
            "metadata": {},
            "outputs": [],
            "source": [
                "%load_ext autoreload\n",
                "%autoreload 2\n",
                "\n",
                "# change directory to the root of the project\n",
                "import os\n",
                "\n",
                "os.chdir(\"..\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "from vqpiano.models.factory import model_factory\n",
                "from omegaconf import OmegaConf\n",
                "from typing import cast\n",
                "import torch\n",
                "from vqpiano.models.segment import SegmentFullSongModel\n",
                "from safetensors.torch import load_file\n",
                "\n",
                "model_config = OmegaConf.load(\"config/simple_ar/model_segment_full_song.yaml\").model\n",
                "model_ = model_factory(model_config)\n",
                "model = cast(SegmentFullSongModel, model_)\n",
                "model.load_state_dict(load_file(r\"wandb\\run-20250513_214542-7xjvhz2d\\files\\checkpoints\\epoch=197-step=1100000.safetensors\"))\n",
                "model.eval()\n",
                "device = 'cuda:0'\n",
                "model.to(device)\n",
                "0"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "src"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "from pathlib import Path\n",
                "from music_data_analysis import Pianoroll\n",
                "\n",
                "\n",
                "# src_path = r\"ignore\\output\\input\\ai.mid\"\n",
                "\n",
                "src_path = \"ignore/output/input/241221.mid\"\n",
                "# labels = 'ABCBCDCE'\n",
                "# lengths = [4,8,8,16,8,4,8,8] # bars\n",
                "labels_and_lengths = 'A4B8C8B16C16D4C8E8'\n",
                "compose_order = [4, 1,2,3,5,6,7, 0]\n",
                "\n",
                "\n",
                "# src_path = \"ignore/output/input/0814_p.mid\"\n",
                "# labels_and_lengths = 'A4B16C8D8E8B16F8'\n",
                "# compose_order = [3,2,1,4,5,0,6]\n",
                "\n",
                "labels = []\n",
                "lengths = []\n",
                "cursor = 0\n",
                "i = 0\n",
                "while i < len(labels_and_lengths):\n",
                "    if labels_and_lengths[i].isalpha():\n",
                "        labels.append(labels_and_lengths[i])\n",
                "        i += 1\n",
                "    else:\n",
                "        # Start collecting digits\n",
                "        num_str = \"\"\n",
                "        while i < len(labels_and_lengths) and labels_and_lengths[i].isdigit():\n",
                "            num_str += labels_and_lengths[i]\n",
                "            i += 1\n",
                "        lengths.append(int(num_str))\n",
                "\n",
                "src_path = Path(src_path)\n",
                "src = Pianoroll.from_midi(src_path)\n",
                "# given_segments = [src]\n",
                "\n",
                "# given_segments = [src.slice(8*32, 16*32),src.slice(0, 8*32)]\n",
                "\n",
                "\n",
                "given_segments = []\n",
                "src_remaining = src.copy()\n",
                "for i in compose_order:\n",
                "    length = lengths[i]\n",
                "    if src_remaining.duration == 0:\n",
                "        break\n",
                "    if src_remaining.duration <= length*32:\n",
                "        given_segments.append(src_remaining)\n",
                "        break\n",
                "    given_segments.append(src_remaining[:length*32])\n",
                "    src_remaining = src_remaining[length*32:]\n",
                "\n",
                "print('labels', labels)\n",
                "print('lengths', lengths)\n",
                "print('compose_order', compose_order)\n",
                "print('given_segments', given_segments)\n",
                "\n",
                "name = f'seed_{src_path.stem}'\n",
                "for i, s in enumerate(given_segments):\n",
                "    assert s.duration == lengths[compose_order[i]]*32, f'{s.duration} != {lengths[compose_order[i]]*32}'\n",
                "\n",
                "# given_segments = []\n",
                "# name = \"From Scratch\"\n",
                "\n",
                "\n",
                "n_sample = 10\n",
                "\n",
                "for i in range(n_sample):\n",
                "\n",
                "    full_song,annotations = model.sample_song(labels=labels, lengths_in_bars=lengths, compose_order=compose_order, given_segments=given_segments)\n",
                "    full_song: Pianoroll\n",
                "    Path(f'ignore/output/{name}').mkdir(parents=True, exist_ok=True)\n",
                "    # log generated segment\n",
                "    full_song.to_midi(f'ignore/output/{name}/{i}.mid', markers=annotations)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "\n",
                "full_song.to_midi('ignore/output/test.mid', markers=annotations)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "context_pr.duration"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "from music_data_analysis.utils import plt\n",
                "\n",
                "\n",
                "plt.imshow(composed_segments_sorted[1][\"pianoroll\"].to_img_tensor())"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "from vqpiano.data.factory import dataloader_factory\n",
                "from omegaconf import OmegaConf\n",
                "\n",
                "dl = dataloader_factory(\n",
                "    dataset_config=OmegaConf.load(\"config/dataset_pop80k_k_pr.yaml\"),\n",
                "    dataloader_config={},\n",
                "    model_config=OmegaConf.load(\"config/latent_diff/model_token.yaml\"),\n",
                ")\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 13,
            "metadata": {},
            "outputs": [],
            "source": [
                "for i, a in enumerate(dl):\n",
                "    if i > 30:\n",
                "        break"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "a[\"pianoroll\"][0].to_midi(\"ignore/output/test.mid\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "a[\"features\"].max()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import matplotlib.pyplot as plt\n",
                "\n",
                "plt.imshow(a[\"features\"].squeeze(0))"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import torch\n",
                "\n",
                "\n",
                "plt.imshow((a[\"features\"] + torch.randn_like(a[\"features\"]) * 0.1).squeeze(0)[:, 5:])"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "a[\"pianoroll\"][0]"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "13",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.13.2"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 2
}
