{
    "cells": [
        {
            "cell_type": "code",
            "execution_count": 7,
            "metadata": {},
            "outputs": [],
            "source": [
                "import music_data_analysis as analysis\n",
                "from music_data_analysis.data.pianoroll import Pianoroll\n",
                "from music_data_analysis import Note\n",
                "from pathlib import Path"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 8,
            "metadata": {},
            "outputs": [],
            "source": [
                "from collections import defaultdict\n",
                "\n",
                "\n",
                "def get_num_overlaps2(a: Pianoroll, b: Pianoroll, pitch_shift: int):\n",
                "    num_overlaps = 0\n",
                "    i = 0\n",
                "    j = 0\n",
                "    a_pitch_to_notes: dict[int, list[Note]] = defaultdict(list)\n",
                "    for note in a.notes:\n",
                "        a_pitch_to_notes[note.pitch].append(note)\n",
                "    b_pitch_to_notes: dict[int, list[Note]] = defaultdict(list)\n",
                "    for note in b.notes:\n",
                "        b_pitch_to_notes[note.pitch + pitch_shift].append(note)\n",
                "\n",
                "    all_pitches = set(a_pitch_to_notes.keys()) | set(b_pitch_to_notes.keys())\n",
                "    for pitch in all_pitches:\n",
                "        a_notes = a_pitch_to_notes[pitch]\n",
                "        b_notes = b_pitch_to_notes[pitch]\n",
                "        i = 0\n",
                "        j = 0\n",
                "        while i < len(a_notes) and j < len(b_notes):\n",
                "            if abs(a_notes[i].onset - b_notes[j].onset) <= 1:\n",
                "                num_overlaps += 1\n",
                "                i += 1\n",
                "                j += 1\n",
                "            elif a_notes[i].onset < b_notes[j].onset:\n",
                "                i += 1\n",
                "            else:\n",
                "                j += 1\n",
                "\n",
                "    denom = max(len(a.notes), len(b.notes))\n",
                "    if denom == 0:\n",
                "        return 0\n",
                "    else:\n",
                "        return num_overlaps / denom\n",
                "\n",
                "\n",
                "def get_num_overlaps(a: Pianoroll, b: Pianoroll, pitch_shift: int):\n",
                "    num_overlaps = 0\n",
                "    i = 0\n",
                "    j = 0\n",
                "\n",
                "    a_notes = []\n",
                "    seen_pitch = [0] * 128\n",
                "    for note in a.notes:\n",
                "        if seen_pitch[note.pitch] < 2:\n",
                "            a_notes.append(note)\n",
                "            seen_pitch[note.pitch] += 1\n",
                "\n",
                "    b_notes = []\n",
                "\n",
                "    seen_pitch = [0] * 128\n",
                "    for note in b.notes:\n",
                "        if seen_pitch[note.pitch] < 2:\n",
                "            b_notes.append(note)\n",
                "            seen_pitch[note.pitch] += 1\n",
                "\n",
                "    i_max = len(a_notes)\n",
                "    j_max = len(b_notes)\n",
                "\n",
                "    while i < i_max and j < j_max:\n",
                "        note_a = a_notes[i]\n",
                "        note_b = b_notes[j]\n",
                "\n",
                "        if note_a.onset < note_b.onset:\n",
                "            i += 1\n",
                "        elif note_a.onset > note_b.onset:\n",
                "            j += 1\n",
                "        else:\n",
                "            if note_a.pitch == note_b.pitch + pitch_shift:\n",
                "                num_overlaps += 1\n",
                "\n",
                "            i += 1\n",
                "            j += 1\n",
                "\n",
                "    denom = (len(a_notes) + len(b_notes)) / 2\n",
                "\n",
                "    if denom == 0:\n",
                "        if len(a.notes) == 0 and len(b.notes) == 0:\n",
                "            return 1\n",
                "        else:\n",
                "            return 0\n",
                "    return num_overlaps / denom\n",
                "\n",
                "\n",
                "def get_overlap_sim(a: Pianoroll, b: Pianoroll):\n",
                "    pitch_shift_search = [0, -12, 12]\n",
                "    num_overlaps_list = []\n",
                "    for pitch_shift in pitch_shift_search:\n",
                "        num_overlaps = get_num_overlaps2(a, b, pitch_shift)\n",
                "        num_overlaps_list.append(num_overlaps)\n",
                "    return max(num_overlaps_list)\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 9,
            "metadata": {},
            "outputs": [],
            "source": [
                "from matplotlib import pyplot as plt\n",
                "import torch\n",
                "\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 10,
            "metadata": {},
            "outputs": [],
            "source": [
                "def get_skyline(pr: Pianoroll, max_slope:float=1, intercept:float=0):\n",
                "    '''\n",
                "    max_slope: octaves per beat\n",
                "    '''\n",
                "    notes = pr.notes\n",
                "\n",
                "    max_slope_semitones_per_frame = max_slope * 12 / pr.frames_per_beat\n",
                "\n",
                "    # filter notes that on top of each frame\n",
                "\n",
                "    result1 = []\n",
                "    for i in range(len(notes)-1):\n",
                "        if notes[i].onset != notes[i+1].onset:\n",
                "            result1.append(notes[i])\n",
                "    result1.append(notes[-1])\n",
                "\n",
                "    result2: list[Note] = []\n",
                "    last_onset = -2147483648\n",
                "    last_pitch = 0\n",
                "    for note in result1:\n",
                "        if (note.pitch - last_pitch + intercept) / (note.onset - last_onset) >= -max_slope_semitones_per_frame:\n",
                "            result2.append(note.copy())\n",
                "            last_onset = note.onset\n",
                "            last_pitch = note.pitch\n",
                "\n",
                "    result3: list[Note] = []\n",
                "    last_onset = 2147483647\n",
                "    last_pitch = 0\n",
                "    for note in reversed(result2):\n",
                "        if (note.pitch - last_pitch + intercept) / (last_onset - note.onset) >= -max_slope_semitones_per_frame:\n",
                "            result3.append(note.copy())\n",
                "            last_onset = note.onset\n",
                "            last_pitch = note.pitch\n",
                "\n",
                "    result3.reverse()\n",
                "\n",
                "    return Pianoroll(result3, beats_per_bar=pr.beats_per_bar, frames_per_beat=pr.frames_per_beat, duration=pr.duration)\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 11,
            "metadata": {},
            "outputs": [],
            "source": [
                "ds = analysis.Dataset(Path(\"../dataset/pop80k_k\"))\n",
                "# song = ds.get_song(\"@Animenzzz/1zKejX-up-k/0_554\")\n",
                "# song = ds.get_song(\"@AnCoongPiano/_MwrgFgL5wo/0_270\")\n",
                "# data/pop80k_k/segmentation/@0AdRiaNleE0/4Ne_JADL0Yc/0_234.json\n",
                "song = ds.get_song(\"@0AdRiaNleE0/4Ne_JADL0Yc/0_234\")\n",
                "# song = ds.songs()[42398]\n",
                "# song = ds.songs()[69145]\n",
                "# song = ds.songs()[35923]\n",
                "\n",
                "# \"W:\\piano-ai\\output\\@Animenzzz\\4UEnnIChm8U\\0_473.mid\"\n",
                "# pr = ds.get_song(\"@Animenzzz/-liXLunc-JQ/0_365\").read_pianoroll(\"pianoroll\")\n",
                "\n",
                "\n",
                "# is_pop = open(\"../dataset/pop80k_k/is_pop.txt\").read().splitlines()\n",
                "# i = 30789\n",
                "# songs = ds.songs()\n",
                "# song = songs[i]\n",
                "# while song.song_name.split(\"/\")[0] not in is_pop:\n",
                "#     i+=1\n",
                "#     song = songs[i]\n",
                "\n",
                "chords = song.read_json(\"chords\")\n",
                "pr = song.read_pianoroll(\"pianoroll\")\n",
                "\n",
                "mat = torch.zeros((pr.duration // 32, pr.duration // 32))\n",
                "skyline = get_skyline(pr)\n",
                "for i in range(pr.duration // 32):\n",
                "    for j in range(i, pr.duration // 32):\n",
                "        sim = (\n",
                "            get_overlap_sim(\n",
                "                skyline.slice(i * 32, (i + 1) * 32), skyline.slice(j * 32, (j + 1) * 32)\n",
                "            )\n",
                "            * 0.5\n",
                "            + get_overlap_sim(\n",
                "                pr.slice(i * 32, (i + 1) * 32), pr.slice(j * 32, (j + 1) * 32)\n",
                "            )\n",
                "            * 0.5\n",
                "        )\n",
                "        mat[i, j] = sim\n",
                "        mat[j, i] = sim"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "pr.duration // 32"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import numpy as np\n",
                "from sklearn.cluster import KMeans\n",
                "\n",
                "\n",
                "import pickle\n",
                "\n",
                "file = song.get_old_path(\"triplet_predictions\")\n",
                "\n",
                "a = pickle.load(open(file, \"rb\"))\n",
                "beats = song.read_json(\"beats\")\n",
                "beats_in_second = torch.tensor(beats['beats'])\n",
                "\n",
                "def second_to_beat(second):\n",
                "    beat = torch.searchsorted(beats_in_second, second)\n",
                "    return int(beat)\n",
                "def second_to_bar(second):\n",
                "    return round(second_to_beat(second)/4)\n",
                "split_points, labels = a[3]\n",
                "split_points = split_points[1:,0]\n",
                "split_points = [second_to_bar(split_point) for split_point in split_points]\n",
                "\n",
                "''''''\n",
                "\n",
                "# plot the mat with the split points\n",
                "names = [\"A\", \"B\", \"C\", \"D\", \"E\", \"F\", \"G\"]\n",
                "plt.imshow(mat, vmax=0.5, vmin=0.2)\n",
                "plt.colorbar()\n",
                "for i, (split, next_split) in enumerate(zip([0] + split_points, split_points + [mat.shape[0]])):\n",
                "    plt.plot([split - 0.5, split - 0.5], [0, mat.shape[1]], \"r--\", alpha=0.5)\n",
                "    plt.plot([0, mat.shape[0]], [split - 0.5, split - 0.5], \"r--\", alpha=0.5)\n",
                "    plt.text(\n",
                "        split + (next_split - split) / 2,\n",
                "        split + (next_split - split) / 2,\n",
                "        # names[labels[split]],\n",
                "        names[labels[i]],\n",
                "        ha=\"center\",\n",
                "        va=\"center\",\n",
                "        fontsize=20,\n",
                "        color=\"#000000\",\n",
                "    )\n",
                "\n",
                "segments = []\n",
                "for i, (split, next_split) in enumerate(zip([0] + split_points, split_points + [mat.shape[0]])):\n",
                "    segments.append({'start': split * 32, 'end': next_split * 32, 'label': labels[i]})\n",
                "\n",
                "\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "A.numpy().max()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import numpy as np\n",
                "import scipy\n",
                "from sklearn.cluster import KMeans\n",
                "\n",
                "ignores = []\n",
                "# A is similarity matrix add adjacency matrix so we favor more connected bars\n",
                "adj = torch.zeros_like(mat)\n",
                "adj.diagonal(0).fill_(1)  # Main diagonal\n",
                "adj.diagonal(1).fill_(1)  # Diagonal +1\n",
                "adj.diagonal(-1).fill_(1)  # Diagonal -1\n",
                "adj_weight = 0.7\n",
                "mat_clamped = torch.clamp(mat, min=0.2)\n",
                "A = mat_clamped * (1 - adj_weight) + adj_weight * adj\n",
                "D = torch.diag(A.sum(dim=1))\n",
                "L = D - A\n",
                "# Using matrix square root manually since torch.linalg doesn't have sqrtm\n",
                "# D_sqrt_inv = torch.diag(torch.pow(torch.diag(D), -0.5))\n",
                "# L = torch.eye(A.shape[0]) - D_sqrt_inv @ A @ D_sqrt_inv\n",
                "\n",
                "\n",
                "eigvals, eigvecs = torch.linalg.eig(L)\n",
                "# Extract the first k eigenvectors of the Laplacian (smallest eigenvalues):\n",
                "# k = 5\n",
                "# d = 5\n",
                "# eigvecs_first_k = eigvecs[:, torch.argsort(eigvals.real)[:k]].real\n",
                "# eigvecs_first_d = eigvecs[:, torch.argsort(eigvals.real)[:d]].real\n",
                "\n",
                "# # remove the ignores\n",
                "# eigvecs = eigvecs[[i not in ignores for i in range(len(eigvecs))], :]\n",
                "\n",
                "# labels: np.ndarray = KMeans(n_clusters=k).fit_predict(eigvecs_first_k.real)\n",
                "\n",
                "\n",
                "max_k = 5\n",
                "\n",
                "eigvals_sorted = torch.sort(eigvals.real)[0]\n",
                "eigval_diff = eigvals_sorted[1:] - eigvals_sorted[:-1]\n",
                "\n",
                "eigval_diff[0]=0 # we don't consider k=1\n",
                "\n",
                "k = int((torch.argmax(eigval_diff[:max_k]) + 1))\n",
                "\n",
                "# Extract the first k eigenvectors of the Laplacian (smallest eigenvalues):\n",
                "eigvecs_first_k = eigvecs[:, torch.argsort(eigvals.real)[:k]].real\n",
                "\n",
                "labels = KMeans(n_clusters=k).fit_predict(eigvecs_first_k)\n",
                "\n",
                "\n",
                "\n",
                "label_order = []\n",
                "seen_labels = set()\n",
                "for i in range(len(labels)):\n",
                "    if labels[i] not in seen_labels:\n",
                "        label_order.append(labels[i])\n",
                "        seen_labels.add(labels[i])\n",
                "labels = [label_order.index(i) for i in labels]\n",
                "\n",
                "split_points = []\n",
                "for i in range(1, len(labels)):\n",
                "    if labels[i] != labels[i - 1]:\n",
                "        split_points.append(i)\n",
                "\n",
                "\n",
                "''''''\n",
                "\n",
                "# plot the mat with the split points\n",
                "names = [\"A\", \"B\", \"C\", \"D\", \"E\", \"F\", \"G\"]\n",
                "plt.imshow(mat)\n",
                "plt.colorbar()\n",
                "for i, (split, next_split) in enumerate(zip([0] + split_points, split_points + [mat.shape[0]])):\n",
                "    plt.plot([split - 0.5, split - 0.5], [0, mat.shape[1]], \"r--\", alpha=0.5)\n",
                "    plt.plot([0, mat.shape[0]], [split - 0.5, split - 0.5], \"r--\", alpha=0.5)\n",
                "    plt.text(\n",
                "        split + (next_split - split) / 2,\n",
                "        split + (next_split - split) / 2,\n",
                "        names[labels[split]],\n",
                "        # names[labels[i]],\n",
                "        ha=\"center\",\n",
                "        va=\"center\",\n",
                "        fontsize=20,\n",
                "        color=\"#000000\",\n",
                "    )\n",
                "\n",
                "segments = []\n",
                "for i, (split, next_split) in enumerate(zip([0] + split_points, split_points + [mat.shape[0]])):\n",
                "    segments.append({'start': split * 32, 'end': next_split * 32, 'label': labels[split]})\n",
                "\n",
                "def calinski_harabasz_index(eigvecs, labels, k):\n",
                "    labels = torch.tensor(labels)\n",
                "    custer_centroids = []\n",
                "    for i in range(k):\n",
                "        custer_centroids.append(eigvecs[labels == i].mean(dim=0))\n",
                "    global_centroid = eigvecs.mean(dim=0)\n",
                "    bcss = 0\n",
                "    wcss = 0\n",
                "    for i in range(k):\n",
                "        bcss += (custer_centroids[i] - global_centroid).pow(2).sum()\n",
                "        wcss += (eigvecs[labels == i] - custer_centroids[i]).pow(2).sum()\n",
                "    print(bcss, wcss)\n",
                "    return (bcss / (k - 1)) / (wcss / (len(eigvecs) - k))\n",
                "\n",
                "for segment in segments:\n",
                "    print(segment['start'], segment['end'], segment['label'])"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "[labels[i] for i in split_points]"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "max_k = 9\n",
                "\n",
                "eigvals_sorted = torch.sort(eigvals.real)[0]\n",
                "eigval_diff = eigvals_sorted[1:] - eigvals_sorted[:-1]\n",
                "\n",
                "eigval_diff[0]=0 # we don't consider k=1\n",
                "\n",
                "optimal_k = np.argmax(eigval_diff[:max_k]) + 1\n",
                "print(f\"optimal_k: {optimal_k}\")\n",
                "\n",
                "plt.plot(range(1, max_k+1), eigval_diff[:max_k])"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 5,
            "metadata": {},
            "outputs": [],
            "source": [
                "from music_data_analysis.processors.segmentation import SegmentationProcessor\n",
                "proc = SegmentationProcessor()\n",
                "proc.process_impl(song)\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "a[3]"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# simulate that human make this music.\n",
                "\n",
                "# First, the composer comes up with the seed segment (possibly chorus).\n",
                "# To identify the seed segment, the model looks for the segment label with most bars in total.\n",
                "# Within segments with this label, it selects the segment that is clost to the middle of the song.\n",
                "import random\n",
                "segment_compose_order = []\n",
                "\n",
                "duration = pr.duration\n",
                "\n",
                "\n",
                "n_bars_per_label = [0] * k\n",
                "for i in range(len(segments)):\n",
                "    n_bars_per_label[segments[i]['label']] += (segments[i]['end'] - segments[i]['start']) // 32\n",
                "\n",
                "print('n_bars_per_label', n_bars_per_label)\n",
                "\n",
                "label = np.argmax(n_bars_per_label)\n",
                "print('label', label)\n",
                "\n",
                "selected_segment = None\n",
                "for segment in segments:\n",
                "    if segment['label'] == label:\n",
                "        if selected_segment is None:\n",
                "            selected_segment = segment\n",
                "        elif abs(segment['start'] - duration // 2) < abs(selected_segment['start'] - duration // 2):\n",
                "            selected_segment = segment\n",
                "\n",
                "segment_compose_order.append(selected_segment)\n",
                "\n",
                "# Next, the composer writes the second-most bars segment.\n",
                "\n",
                "\n",
                "label = np.argsort(n_bars_per_label)[-2]\n",
                "print('label', label)\n",
                "\n",
                "selected_segment = None\n",
                "for segment in segments:\n",
                "    if segment['label'] == label:\n",
                "        if selected_segment is None:\n",
                "            selected_segment = segment\n",
                "        elif abs(segment['start'] - duration // 2) < abs(selected_segment['start'] - duration // 2):\n",
                "            selected_segment = segment\n",
                "\n",
                "segment_compose_order.append(selected_segment)\n",
                "\n",
                "print('segment_compose_order', segment_compose_order)\n",
                "\n",
                "# randomly permute the remaining segments\n",
                "remaining_segments = [segment for segment in segments if segment not in segment_compose_order]\n",
                "random.shuffle(remaining_segments)\n",
                "\n",
                "segment_compose_order.extend(remaining_segments)\n",
                "\n",
                "print('segment_compose_order', segment_compose_order)\n",
                "\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# for training, sample a segment from the segment_compose_order\n",
                "# target_index = random.randint(0, len(segment_compose_order) - 1)\n",
                "target_index = 2\n",
                "target_segment = segment_compose_order[target_index]\n",
                "\n",
                "\n",
                "already_composed_segments = segment_compose_order[:target_index]\n",
                "\n",
                "nearest_left_segment = None\n",
                "nearest_left_segment_distance = float('inf')\n",
                "for segment in reversed(already_composed_segments):\n",
                "    if segment['end'] > target_segment['start']:\n",
                "        continue\n",
                "    left_segment_distance = target_segment['start'] - segment['end']\n",
                "    if left_segment_distance < nearest_left_segment_distance:\n",
                "        nearest_left_segment_distance = left_segment_distance\n",
                "        nearest_left_segment = segment\n",
                "\n",
                "nearest_right_segment = None\n",
                "nearest_right_segment_distance = float('inf')\n",
                "for segment in already_composed_segments:\n",
                "    if segment['start'] < target_segment['end']:\n",
                "        continue\n",
                "    right_segment_distance = segment['start'] - target_segment['end']\n",
                "    if right_segment_distance < nearest_right_segment_distance:\n",
                "        nearest_right_segment_distance = right_segment_distance\n",
                "        nearest_right_segment = segment\n",
                "\n",
                "reference_segment = None\n",
                "for segment in already_composed_segments:\n",
                "    if segment['label'] == target_segment['label']:\n",
                "        reference_segment = segment\n",
                "        break\n",
                "\n",
                "if target_index == 0:\n",
                "    seed_segment = None\n",
                "else:\n",
                "    seed_segment = segment_compose_order[0]\n",
                "\n",
                "print('target_index', target_index)\n",
                "print('left_segment', nearest_left_segment)\n",
                "print('right_segment', nearest_right_segment)\n",
                "print('seed_segment', seed_segment)\n",
                "print('reference_segment', reference_segment)\n",
                "\n",
                "# plot on the mat\n",
                "plt.figure(figsize=(8, 8))\n",
                "plt.gca().set_facecolor('black')\n",
                "# plt.gcf().set_facecolor('black')\n",
                "\n",
                "plt.imshow(mat, cmap='gray', alpha=0.5)\n",
                "\n",
                "annotation_per_segment = ['']*len(segments)\n",
                "for name, segment in zip(['tar', 'l', 'r', 'seed', 'ref'], [target_segment, nearest_left_segment, nearest_right_segment, seed_segment, reference_segment]):\n",
                "    if segment is None:\n",
                "        continue\n",
                "    annotation_per_segment[segments.index(segment)] += f',{name}'\n",
                "    # plt.text((segment['start'] + (segment['end'] - segment['start']) / 2) / 32, (segment['start'] + (segment['end'] - segment['start']) / 2) / 32+2, name, ha='center', va='center', fontsize=20, color=\"#ff7700\")\n",
                "\n",
                "for i, annotation in enumerate(annotation_per_segment):\n",
                "    plt.text((segments[i]['start'] + segments[i]['end']) / 2 / 32, (segments[i]['start'] + segments[i]['end']) / 2 / 32, annotation[1:], ha='center', va='center', fontsize=20, color=\"#00ffff\")\n",
                "\n",
                "for i, (split, next_split) in enumerate(zip([0] + split_points, split_points + [mat.shape[0]])):\n",
                "    plt.plot([split - 0.5, split - 0.5], [0, mat.shape[1]], \"r--\", alpha=0.5)\n",
                "    plt.plot([0, mat.shape[0]], [split - 0.5, split - 0.5], \"r--\", alpha=0.5)\n",
                "    plt.text(\n",
                "        split + (next_split - split) / 2,\n",
                "        split + (next_split - split) / 10,\n",
                "        names[labels[split]]+f'({segment_compose_order.index(segments[i])})',\n",
                "        ha=\"center\",\n",
                "        va=\"center\",\n",
                "        fontsize=15,\n",
                "        color=\"#00ff00\",\n",
                "    )\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 10,
            "metadata": {},
            "outputs": [],
            "source": []
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "a"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "split_points"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 32,
            "metadata": {},
            "outputs": [],
            "source": []
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "\n",
                "\n",
                "print(second_to_beat(500000))\n",
                "\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "len(beats_in_second)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 523,
            "metadata": {},
            "outputs": [],
            "source": [
                "from numpy import random\n",
                "\n",
                "\n",
                "for _ in range(20):\n",
                "    i = random.randint(0, len(ds) - 1)\n",
                "    song = ds.songs()[i]\n",
                "    pr = song.read_pianoroll(\"pianoroll\")\n",
                "    pr.to_midi(f\"/home/eri24816/segment_full_song/ignore/output/sample/{i}.mid\")\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 33,
            "metadata": {},
            "outputs": [],
            "source": [
                "def cut(W: torch.Tensor, A: torch.Tensor, B: torch.Tensor):\n",
                "    s = 0\n",
                "    for u in A:\n",
                "        for v in B:\n",
                "            s += W[u, v]\n",
                "    return s\n",
                "\n",
                "\n",
                "def assoc(W: torch.Tensor, A: torch.Tensor):\n",
                "    return W.sum(1)[A].sum()\n",
                "\n",
                "\n",
                "def ncut(W: torch.Tensor, A: torch.Tensor, B: torch.Tensor):\n",
                "    return cut(W, A, B) / assoc(W, A) + cut(W, A, B) / assoc(W, B)\n",
                "\n",
                "\n",
                "def search_cut(W: torch.Tensor, eigvec: torch.Tensor, num_search: int = 10) -> tuple[torch.Tensor, torch.Tensor, float]:\n",
                "    best_cut_point = 0\n",
                "    best_ncut = float(\"inf\")\n",
                "\n",
                "    for cut_point in torch.linspace(eigvec.min(), eigvec.max(), num_search):\n",
                "        A = torch.where(eigvec < cut_point)[0]\n",
                "        B = torch.where(eigvec >= cut_point)[0]\n",
                "        ncut_for_this_cut_point = ncut(W, A, B)\n",
                "        if ncut_for_this_cut_point < best_ncut:\n",
                "            best_ncut = ncut_for_this_cut_point.item()\n",
                "            best_cut_point = cut_point\n",
                "    res_A = torch.where(eigvec < best_cut_point)[0]\n",
                "    res_B = torch.where(eigvec >= best_cut_point)[0]\n",
                "    return res_A, res_B, best_ncut\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# W = mat[:27, :27] + 0.1\n",
                "\n",
                "\n",
                "def ncut_eig(W):\n",
                "    D = torch.diag(W.sum(dim=1))\n",
                "    D_inv = torch.diag(1 / torch.diag(D))\n",
                "    eigvals, eigvecs = torch.linalg.eig(D_inv @ (D - W))\n",
                "    # use the second smallest eigenvalue's eigenvector\n",
                "    eigvec = eigvecs[:, torch.argsort(eigvals.real)[1]].real\n",
                "    return eigvec\n",
                "\n",
                "\n",
                "def remove_index(mat, index):\n",
                "    \"\"\"\n",
                "    Remove the index-th row and column from the matrix\n",
                "    \"\"\"\n",
                "    row_removed = torch.cat([mat[:index, :], mat[index + 1 :, :]])\n",
                "    col_removed = torch.cat([row_removed[:, :index], row_removed[:, index + 1 :]], dim=1)\n",
                "    return col_removed\n",
                "\n",
                "\n",
                "def remove_indices(mat, indices):\n",
                "    \"\"\"\n",
                "    Remove the indices-th rows and columns from the matrix\n",
                "    \"\"\"\n",
                "    for index in sorted(indices, reverse=True):\n",
                "        mat = remove_index(mat, index)\n",
                "    return mat\n",
                "\n",
                "\n",
                "W = mat\n",
                "eigvec = ncut_eig(W)\n",
                "plt.plot(eigvec)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "eigvec = ncut_eig(remove_indices(W, [0, 1]))\n",
                "plt.plot(eigvec)\n",
                "\n",
                "A, B, ncut_val = search_cut(W, eigvec)\n",
                "plt.imshow(W, vmax=0.5)\n",
                "plt.plot(A, torch.zeros(len(A)), \"ro\")\n",
                "plt.plot(B, torch.zeros(len(B)), \"bo\")\n",
                "plt.show()\n",
                "print(ncut_val)\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 39,
            "metadata": {},
            "outputs": [],
            "source": [
                "import pprint\n",
                "\n",
                "\n",
                "def recursive_ncut(W: torch.Tensor, real_indices: torch.Tensor | None = None, stop_ncut: float = 1000):\n",
                "    \"\"\"\n",
                "    Recursively cut the matrix until the ncut value is larger than the stop_ncut\n",
                "    Args:\n",
                "        W (torch.Tensor): The weight matrix\n",
                "        stop_ncut (float, optional): The ncut value to stop the recursion. Defaults to 1.\n",
                "    \"\"\"\n",
                "    if real_indices is None:\n",
                "        real_indices = torch.arange(W.shape[0])\n",
                "\n",
                "    if W.shape[0] <= 2:\n",
                "        return real_indices.tolist()\n",
                "\n",
                "    eigvec = ncut_eig(W)\n",
                "    A, B, ncut_val = search_cut(W, eigvec, num_search=20)\n",
                "    if ncut_val > stop_ncut:\n",
                "        return real_indices.tolist()\n",
                "    else:\n",
                "        A_indices = real_indices[A]\n",
                "        B_indices = real_indices[B]\n",
                "        return [\n",
                "            recursive_ncut(remove_indices(W, B), A_indices, stop_ncut),\n",
                "            recursive_ncut(remove_indices(W, A), B_indices, stop_ncut),\n",
                "        ]\n",
                "\n",
                "\n",
                "res = recursive_ncut(mat + 0.1)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "pprint.pprint(res)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "from typing import Callable\n",
                "\n",
                "\n",
                "class Node:\n",
                "    def __init__(\n",
                "        self,\n",
                "        parent: \"Node|None\" = None,\n",
                "        tag: str | None = None,\n",
                "        tree: \"Tree|None\" = None,\n",
                "    ):\n",
                "        self.tag = tag\n",
                "        self.parent = parent\n",
                "        self.tree = tree\n",
                "        self.children = []\n",
                "        if self.tree is None:\n",
                "            assert self.parent is not None\n",
                "            self.tree = self.parent.tree\n",
                "        if self.tag is not None:\n",
                "            self.tree.nodes[self.tag] = self\n",
                "        if self.parent is not None:\n",
                "            self.parent.children.append(self)\n",
                "\n",
                "    def __str__(self):\n",
                "        indent_first = \"│\" + \"  \" * 1\n",
                "        indent = \"│\" + \"  \" * 1\n",
                "        indent_last = \"   \"\n",
                "        if self.tag is None:\n",
                "            res = \"\"\n",
                "        else:\n",
                "            res = self.tag\n",
                "        if len(self.children) > 0:\n",
                "            first_child_str = self.children[0].__str__()\n",
                "            if len(self.children) > 1:\n",
                "                first_child_prefix = \"┬──\"\n",
                "            else:\n",
                "                first_child_prefix = \"───\"\n",
                "            first_child_line = first_child_prefix + first_child_str.replace(\"\\n\", \"\\n\" + indent_first) + \"\\n\"\n",
                "\n",
                "            res += first_child_line\n",
                "            for child in self.children[1:-1]:\n",
                "                child_str = child.__str__()\n",
                "                res += \"├──\" + child_str.replace(\"\\n\", \"\\n\" + indent)\n",
                "                res += \"\\n\"\n",
                "            last_child_str = self.children[-1].__str__()\n",
                "            res += \"└──\" + last_child_str.replace(\"\\n\", \"\\n\" + indent_last)\n",
                "        return res\n",
                "\n",
                "\n",
                "class Tree:\n",
                "    def __init__(self):\n",
                "        self.nodes = {}\n",
                "        self.root = Node(None, None, self)\n",
                "\n",
                "    def get_depth(self, node: Node):\n",
                "        depth = 0\n",
                "        while node.parent is not None:\n",
                "            node = node.parent\n",
                "            depth += 1\n",
                "        return depth\n",
                "\n",
                "\n",
                "tree = Tree()\n",
                "\n",
                "# plot the result, which is list of lists... of indices\n",
                "\n",
                "\n",
                "def add_to_tree(\n",
                "    tree: Tree,\n",
                "    parent: Node,\n",
                "    indices: list,\n",
                "    name_func: Callable[[int], str] = lambda x: str(x),\n",
                "):\n",
                "    if isinstance(indices, int):\n",
                "        Node(parent, name_func(indices))\n",
                "    elif len(indices) == 1:\n",
                "        Node(parent, name_func(indices[0]), tree)\n",
                "    else:\n",
                "        left, right = indices\n",
                "        node = Node(parent, None, tree)\n",
                "        add_to_tree(tree, node, left, name_func)\n",
                "        add_to_tree(tree, node, right, name_func)\n",
                "\n",
                "\n",
                "add_to_tree(tree, tree.root, res, lambda x: str(x + 1))\n",
                "print(tree.root)\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "def tree_distance(tree: Tree, i: int | str, j: int | str):\n",
                "    if isinstance(i, int):\n",
                "        i = str(i)\n",
                "    if isinstance(j, int):\n",
                "        j = str(j)\n",
                "    a = tree.nodes[i]\n",
                "    b = tree.nodes[j]\n",
                "    a_search = a\n",
                "    b_search = b\n",
                "    while a_search != b_search:\n",
                "        if tree.get_depth(a_search) > tree.get_depth(b_search):\n",
                "            a_search = a_search.parent\n",
                "        else:\n",
                "            b_search = b_search.parent\n",
                "    return tree.get_depth(a) + tree.get_depth(b) - 2 * tree.get_depth(a_search)\n",
                "\n",
                "\n",
                "print(tree_distance(tree, 21, 95))"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "def merge_score(tree: Tree, i: int, j: int):\n",
                "    s = 0\n",
                "    for d in range(-min(i, j) + 1, len(tree.nodes) - max(i, j) + 1):\n",
                "        if d == 0:\n",
                "            continue\n",
                "        # s += 2 ** -(tree_distance(tree, i, i+d) + tree_distance(tree, j, j+d))\n",
                "        s += 20 ** ((mat[i - 1, i + d - 1] + mat[j - 1, j + d - 1]) - 1)\n",
                "    return s\n",
                "\n",
                "\n",
                "print(merge_score(tree, 63, 64))"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "m = torch.zeros((len(tree.nodes), len(tree.nodes)))\n",
                "for i in range(1, len(tree.nodes) + 1 - 1):\n",
                "    j = i + 1\n",
                "    for d in range(-min(i, j) + 1, len(tree.nodes) - max(i, j) + 1):\n",
                "        base = 10\n",
                "        if d != 0:\n",
                "            # m[i, i+d] = base ** -(tree_distance(tree, i, i+d) + tree_distance(tree, j, j+d))\n",
                "            m[i, i + d] = base ** ((mat[i - 1, i + d - 1] + mat[j - 1, j + d - 1]) - 1)\n",
                "\n",
                "plt.imshow(m[:30, :30])\n",
                "plt.colorbar()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "tree_distance(tree, 2, 8)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "l = []\n",
                "for i in range(1, len(tree.nodes) + 1 - 1):\n",
                "    j = i + 1\n",
                "    l.append(merge_score(tree, i, j))\n",
                "plt.plot(l[:30])\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "merge_score(tree, 2, 3)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "plt.imshow(mat[:30, :30], vmax=0.5)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "best_cut_point = search_cut(W, eigvec)\n",
                "print(best_cut_point)"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.13.2"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 2
}
