{
    "cells": [
        {
            "cell_type": "code",
            "execution_count": 1,
            "metadata": {},
            "outputs": [],
            "source": [
                "%load_ext autoreload\n",
                "%autoreload 2\n",
                "\n",
                "# change directory to the root of the project\n",
                "import os\n",
                "\n",
                "os.chdir(\"..\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "from pathlib import Path\n",
                "import dotenv\n",
                "from omegaconf import OmegaConf\n",
                "from vqpiano.data.dataset import FullSongPianorollDataset\n",
                "from vqpiano.models.factory import model_factory\n",
                "\n",
                "from vqpiano.models.ae import EncoderDecoder\n",
                "from vqpiano.models.utils import load_ckpt_state_dict\n",
                "\n",
                "model_config = OmegaConf.load(\"config/latent_diff/model_token.yaml\")\n",
                "dataset_config = OmegaConf.load(\"config/latent_diff/dataset_pop80k_k_fullsong.yaml\")\n",
                "\n",
                "model_ = model_factory(model_config.model)\n",
                "assert isinstance(model_, EncoderDecoder)\n",
                "model = model_\n",
                "\n",
                "model.load_state_dict(\n",
                "    load_ckpt_state_dict(\n",
                "        # Path(\"wandb/run-20250328_110212-x8rqu2qc/files/checkpoints/epoch=2-step=530000.safetensors\"),\n",
                "        Path(\"wandb/run-20250404_013005-i41ffa2m/files/checkpoints/epoch=4-step=1000000.ckpt\"),\n",
                "        unwrap_lightning=True,\n",
                "    )\n",
                ")\n",
                "ds = FullSongPianorollDataset(Path(dataset_config.path), props=[\"pianoroll\"])\n",
                "_ = model.eval()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "ds[6][\"pianoroll\"].to_midi(\"ignore/output/gt.mid\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "pr"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import torch\n",
                "from vqpiano.models.representation import SymbolicRepresentation\n",
                "import matplotlib.pyplot as plt\n",
                "\n",
                "\n",
                "# song, bar_idx1, bar_idx2 = '@Animenzzz/5Ggnzs2hP3s/0_365', 28, 63\n",
                "song, bar_idx1, bar_idx2 = \"@Animenzzz/3KpFbty0t_8/0_347\", 29, 65\n",
                "# pr = ds.ds.get_song(song).read_pianoroll(\"pianoroll\", frames_per_beat=8)\n",
                "pr = ds[0][\"pianoroll\"]\n",
                "\n",
                "gt = SymbolicRepresentation.from_pianorolls(list(pr.iter_over_bars_pr()))\n",
                "\n",
                "with torch.no_grad():\n",
                "    model: EncoderDecoder\n",
                "    latent = model.encode(gt)\n",
                "\n",
                "# plot similarity matrix\n",
                "latent_normalized = latent / latent.norm(dim=1, keepdim=True)\n",
                "cosine_similarity = latent_normalized @ latent_normalized.T\n",
                "plt.imshow(cosine_similarity, vmin=0.1, vmax=0.3)\n",
                "plt.colorbar()\n",
                "plt.show()\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "latent = latent.clone()\n",
                "k = 4\n",
                "rate = 0.1\n",
                "for _ in range(5):\n",
                "    diff = latent[:, None, :] - latent[None, :, :]\n",
                "    euclidean_distance = diff.norm(dim=2, p=2)\n",
                "    old_latent = latent.clone()\n",
                "    for i in range(latent.shape[0]):\n",
                "        nearest_k_idx = torch.argsort(euclidean_distance[i])[1 : k + 1]\n",
                "        latent[i] = old_latent[i] + rate * (old_latent[nearest_k_idx].mean(dim=0) - old_latent[i])\n",
                "\n",
                "    latent_normalized = latent / latent.norm(dim=1, keepdim=True)\n",
                "    cosine_similarity = latent_normalized @ latent_normalized.T\n",
                "\n",
                "plt.imshow(cosine_similarity, vmin=0.1, vmax=0.3)\n",
                "plt.colorbar()\n",
                "plt.show()\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "model.decode_autoregressive(latent[:10], 4).to_midi(21, \"ignore/output/reconst2.mid\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# euclidean distance\n",
                "diff = latent[:, None, :] - latent[None, :, :]\n",
                "euclidean_distance = diff.norm(dim=2, p=2)\n",
                "plt.imshow(-euclidean_distance)\n",
                "plt.colorbar()\n",
                "plt.show()\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "z1 = latent[bar_idx1]\n",
                "z2 = latent[bar_idx2]\n",
                "lerp_n = 10\n",
                "z = torch.stack([z1.lerp(z2, i / (lerp_n - 1)) for i in range(lerp_n)])  # (10,dim)\n",
                "prompt = SymbolicRepresentation.from_pianorolls([pr.slice((bar_idx1 - 4) * 32, (bar_idx1) * 32)])\n",
                "\n",
                "results = []\n",
                "for z_i in z:\n",
                "    z_i = z_i.unsqueeze(0)\n",
                "    with torch.no_grad():\n",
                "        generated = model.decoder.sample(duration=prompt.duration + model.target_duration, prompt=prompt, condition=z_i)\n",
                "        results.append(generated.to_pianoroll(min_pitch=21).slice(4 * 32, 5 * 32))\n",
                "\n",
                "result = results[0]\n",
                "for i in range(1, len(results)):\n",
                "    result |= results[i]\n",
                "\n",
                "plt.imshow(result.to_img_tensor())\n",
                "plt.show()\n",
                "\n",
                "result.to_midi(\"ignore/output/lerp.mid\")\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "result.show()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "pr.slice(0, 30 * 32).to_midi(\"ignore/output/gt.mid\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "def reconstruct_autoregressive(\n",
                "    model: EncoderDecoder,\n",
                "    latents: torch.Tensor,\n",
                "    n_prompt_bars: int,\n",
                "    given_prompt_bars: list[SymbolicRepresentation] | None = None,\n",
                "):\n",
                "    \"\"\"\n",
                "    if given_prompt_bars is None, the first iterations the model will receive empty bars as prompts. It will feel\n",
                "    generating the beginning of the piece.\n",
                "\n",
                "    To make the model generate bars from the middle of the piece, pass the previous bars as given_prompt_bars.\n",
                "    \"\"\"\n",
                "    bars = []\n",
                "\n",
                "    if given_prompt_bars is None:\n",
                "        for i in range(n_prompt_bars):\n",
                "            bar = SymbolicRepresentation(device=latents.device)\n",
                "            for _ in range(32):\n",
                "                bar.add_frame()\n",
                "            bars.append(bar)\n",
                "    else:\n",
                "        assert len(given_prompt_bars) == n_prompt_bars, f\"{len(given_prompt_bars)} != {n_prompt_bars}\"\n",
                "        bars = given_prompt_bars.copy()\n",
                "\n",
                "    for i in range(len(latents)):\n",
                "        prompt = SymbolicRepresentation.cat(bars[i : i + n_prompt_bars])\n",
                "\n",
                "        prediction = model.decoder.sample(\n",
                "            duration=prompt.duration + model.target_duration, prompt=prompt, condition=latents[i].unsqueeze(0)\n",
                "        )\n",
                "        assert prediction.duration == prompt.duration + model.target_duration\n",
                "        bars.append(prediction[:, prompt.length :])\n",
                "\n",
                "    if given_prompt_bars is None:\n",
                "        # remove the padding bars\n",
                "        return SymbolicRepresentation.cat(bars[n_prompt_bars:])\n",
                "    else:\n",
                "        return SymbolicRepresentation.cat(bars)\n",
                "\n",
                "\n",
                "pr = ds[3715].slice(0, 30 * 2)\n",
                "\n",
                "pr.to_midi(\"ignore/output/gt.mid\")\n",
                "\n",
                "gt = SymbolicRepresentation.from_pianorolls(list(pr.iter_over_bars_pr()))\n",
                "\n",
                "\n",
                "with torch.no_grad():\n",
                "    latent = model.encode(gt)\n",
                "\n",
                "latent_bias = torch.zeros_like(latent)\n",
                "# latent_bias[:,14] = 1\n",
                "res = reconstruct_autoregressive(model, latent + latent_bias, 4)\n",
                "res.to_midi(21, \"ignore/output/reconst1.mid\")"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "13",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.13.2"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 2
}
